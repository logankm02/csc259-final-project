{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logan Kinajil-Moran CSC259 Final Project\n",
    "\n",
    "# Video Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original File Size: 45.62MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Get initial size (using Mac Byte Division)\n",
    "file_size = os.path.getsize(\"akiyo_cif.y4m\") / (1000 * 1000) \n",
    "\n",
    "print(f\"Original File Size: {file_size:.2f}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Frames into an Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get frames into an array\n",
    "def get_vid_info(yuv_filename):\n",
    "    frame_marker = b'FRAME\\n' \n",
    "\n",
    "    # Open and read the header\n",
    "    with open(yuv_filename, \"rb\") as file:\n",
    "        # Read the entire file to find where the frame data starts\n",
    "        content = file.read()\n",
    "\n",
    "    # Convert the content to a string to parse it\n",
    "    content_str = content.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    # Find the end of the main header\n",
    "    header_end = content_str.find(\"\\n\") + 1  # Include the newline character\n",
    "\n",
    "    # Calculate YUV frame size\n",
    "    # Using YUV 4:4:4\n",
    "    width = int(content_str.split()[1].strip(\"W\"))\n",
    "    height = int(content_str.split()[2].strip(\"H\"))\n",
    "    y_plane_size = width * height\n",
    "    uv_plane_size = width * height\n",
    "    frame_size = y_plane_size + 2 * uv_plane_size\n",
    "\n",
    "    # Read YUV frames\n",
    "    frames = []\n",
    "    with open(yuv_filename, \"rb\") as yuv_file:\n",
    "        # Skip the header\n",
    "        header = yuv_file.read(int(header_end))\n",
    "        while True:\n",
    "            # Read the FRAME marker\n",
    "            marker = yuv_file.read(len(frame_marker))\n",
    "\n",
    "            # Read the raw YUV frame data\n",
    "            frame_data = yuv_file.read(frame_size)\n",
    "            if len(frame_data) < frame_size:\n",
    "                # All frames have been read\n",
    "                break\n",
    "\n",
    "            frames.append(frame_data)\n",
    "\n",
    "    return frames, header, width, height\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'YUV4MPEG2 W352 H288 F30000:1001 Ip A128:117\\n'\n"
     ]
    }
   ],
   "source": [
    "frames, header, width, height = get_vid_info(\"akiyo_cif.y4m\")\n",
    "\n",
    "print(header)\n",
    "\n",
    "def load_frame(frame, width=width, height=height):\n",
    "    y_size = width * height\n",
    "    uv_size = (width) * (height)\n",
    "    \n",
    "    y = np.frombuffer(frame[0:y_size], dtype=np.uint8).reshape((height, width))\n",
    "    u = np.frombuffer(frame[y_size:y_size + uv_size], dtype=np.uint8).reshape((height, width))\n",
    "    v = np.frombuffer(frame[y_size + uv_size:], dtype=np.uint8).reshape((height, width))\n",
    "    \n",
    "    return y, u, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def frames_into_bytes(frames):\n",
    "    byte_frames = []\n",
    "    for frame in frames:\n",
    "        y, u, v = frame\n",
    "        byte_frames.append(y.astype(np.uint8).tobytes() +\n",
    "                                u.astype(np.uint8).tobytes() +\n",
    "                                v.astype(np.uint8).tobytes())\n",
    "    return byte_frames\n",
    "\n",
    "\n",
    "def get_output_video(frames, output_name, width=width, height=height, framerate=\"30000:1001\", chroma=\"C420\"):\n",
    "    frame_marker = b'FRAME\\n'\n",
    "    output_path = f\"{output_name}.y4m\"\n",
    "    header = f\"YUV4MPEG2 W{width} H{height} F{framerate} Ip A128:117\\n\".encode('utf-8')\n",
    "\n",
    "    with open(f\"{output_name}.y4m\", \"wb\") as output_video:\n",
    "        output_video.write(header)\n",
    "        for frame in frames:\n",
    "            output_video.write(frame_marker)\n",
    "            output_video.write(frame)\n",
    "\n",
    "    print(f\"Size of {output_path}: {os.path.getsize(output_path) / (1000 * 1000):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "352\n",
      "Size of subsampled_test.y4m: 45.62\n"
     ]
    }
   ],
   "source": [
    "# chroma subsampling\n",
    "print(height)\n",
    "print(width)\n",
    "\n",
    "def chroma_subsample_411(plane):\n",
    "    return plane[:, ::4]  # Take every 4th pixel horizontally\n",
    "\n",
    "# Chroma subsampling for 4:2:0 (downsample both horizontally and vertically by 2)\n",
    "def chroma_subsample_420(plane):\n",
    "    return plane[::2, ::2]  # Take every 2nd pixel horizontally and vertically\n",
    "\n",
    "def chroma_upsample_420(plane):\n",
    "    upsampled = np.zeros((height, width), dtype=plane.dtype)\n",
    "    \n",
    "    # Copy values to every 2x2 block\n",
    "    # Safe upsampling\n",
    "    for i in range(height // 2):\n",
    "        for j in range(width // 2):\n",
    "            y_idx = i * 2\n",
    "            x_idx = j * 2\n",
    "            upsampled[y_idx:y_idx+2, x_idx:x_idx+2] = plane[i,j]\n",
    "    \n",
    "    return upsampled\n",
    "\n",
    "def apply_chroma_subsampling(frames, chroma_subsampling_type):\n",
    "    subsampled_frames = []\n",
    "\n",
    "    if chroma_subsampling_type == \"C420\":\n",
    "        for frame in frames:\n",
    "            y, u, v = load_frame(frame)\n",
    "            u_sub = chroma_subsample_420(u)\n",
    "            v_sub = chroma_subsample_420(v)\n",
    "            subsampled_frames.append(y.astype(np.uint8).tobytes() +\n",
    "                                     u_sub.astype(np.uint8).tobytes() +\n",
    "                                     v_sub.astype(np.uint8).tobytes())\n",
    "    \n",
    "    if chroma_subsampling_type == \"C411\":\n",
    "            for frame in frames:\n",
    "                y, u, v = load_frame(frame)\n",
    "                u_sub = chroma_subsample_411(u)\n",
    "                v_sub = chroma_subsample_411(v)\n",
    "                subsampled_frames.append(y.astype(np.uint8).tobytes() +\n",
    "                                        u_sub.astype(np.uint8).tobytes() +\n",
    "                                        v_sub.astype(np.uint8).tobytes())\n",
    "    \n",
    "    return subsampled_frames\n",
    "\n",
    "subsampled_frames = apply_chroma_subsampling(frames, \"C411\") \n",
    "get_output_video(frames, \"subsampled_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the frame rate\n",
    "\n",
    "def reduce_frame_rate(frames, rate):\n",
    "    return frames[::rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Helper function to apply DFT to a block\n",
    "def apply_dft_to_block(block):\n",
    "    # Apply 2D DFT and shift the zero-frequency component to the center\n",
    "    dft = np.fft.fft2(block)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "    # Apply a threshold to filter out small frequencies\n",
    "    threshold = 0.01 * np.max(np.abs(dft_shift))\n",
    "    compressed_dft = np.where(np.abs(dft_shift) > threshold, dft_shift, 0)\n",
    "\n",
    "    return compressed_dft\n",
    "\n",
    "# Helper function to reconstruct a block from compressed DFT\n",
    "def reconstruct_block_from_dft(compressed_dft):\n",
    "    # Inverse DFT to reconstruct the image from compressed DFT\n",
    "    dft_ishift = np.fft.ifftshift(compressed_dft)\n",
    "    reconstructed_block = np.abs(np.fft.ifft2(dft_ishift))\n",
    "\n",
    "    # Normalize to the range [0, 255] and convert to uint8\n",
    "    reconstructed_block = np.clip(reconstructed_block, 0, 255)\n",
    "    return reconstructed_block\n",
    "\n",
    "# Quantize the DFT coefficients for each block\n",
    "def quantize_dft(dft_block, quantization_level=10):\n",
    "    # Quantize the DFT coefficients\n",
    "    return np.round(dft_block / quantization_level) * quantization_level\n",
    "\n",
    "# Apply compression (DFT + quantization) to each block in the frame\n",
    "def apply_compression_to_frame(frame, block_size=16, quantization_level=10):\n",
    "    # Prepare an array to store the compressed blocks\n",
    "    compressed_frame = np.zeros_like(frame)\n",
    "\n",
    "    # Iterate over the frame in blocks\n",
    "    for y in range(0, height, block_size):\n",
    "        for x in range(0, width, block_size):\n",
    "            # Extract the block from the frame\n",
    "            block = frame[y:y+block_size, x:x+block_size]\n",
    "            \n",
    "            # Apply DFT and quantization\n",
    "            compressed_dft = apply_dft_to_block(block)\n",
    "            quantized_dft = quantize_dft(compressed_dft, quantization_level)\n",
    "            \n",
    "            # Reconstruct the block and store it in the compressed frame\n",
    "            compressed_block = reconstruct_block_from_dft(quantized_dft)\n",
    "            compressed_frame[y:y+block_size, x:x+block_size] = compressed_block\n",
    "\n",
    "    return compressed_frame\n",
    "\n",
    "# Apply the compression (DFT + quantization) to Y, U, and V channels of the video frames\n",
    "def apply_compression_to_video(frames, width, height, block_size=16, quantization_level=20):\n",
    "    compressed_frames = []\n",
    "    for frame in frames:\n",
    "        y, u, v = load_frame(frame, width, height)\n",
    "        \n",
    "        # Apply compression to Y, U, and V planes independently\n",
    "        y_compressed = apply_compression_to_block(y, block_size, quantization_level)\n",
    "        u_compressed = apply_compression_to_block(u, block_size, quantization_level)\n",
    "        v_compressed = apply_compression_to_block(v, block_size, quantization_level)\n",
    "        \n",
    "        # Ensure all values are clamped and in uint8 range before storing\n",
    "        y_compressed = np.clip(y_compressed, 0, 255).astype(np.uint8)\n",
    "        u_compressed = np.clip(u_compressed, 0, 255).astype(np.uint8)\n",
    "        v_compressed = np.clip(v_compressed, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # Append the compressed Y, U, V planes to the list of frames\n",
    "        compressed_frames.append(\n",
    "            y_compressed.tobytes() +\n",
    "            u_compressed.tobytes() +\n",
    "            v_compressed.tobytes()\n",
    "        )\n",
    "    \n",
    "    return compressed_frames\n",
    "\n",
    "# compressed_frames = apply_compression_to_video(frames, width, height, block_size=16, quantization_level=10)\n",
    "# get_output_video(compressed_frames, \"dft_block_compressed_video\", width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes encoded frames to an output file\n",
    "def write_encoded_frames(encoded_blocks, u, v, width, height, block_size=16):\n",
    "    for value in encoded_blocks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:15<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "BLOCK_SIZE = 16\n",
    "SEARCH_RANGE = 8\n",
    "DCT_BLOCK_SIZE = 8\n",
    "\n",
    "# Quantization Matrix (for DCT)\n",
    "QUANTIZATION_MATRIX = np.array([\n",
    "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "    [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "])\n",
    "\n",
    "### MOTION ESTIMATION AND COMPENSATION ###\n",
    "def motion_estimation(frame1, frame2, block_size=BLOCK_SIZE, search_range=SEARCH_RANGE):\n",
    "    motion_vectors = np.zeros((height // block_size, width // block_size, 2), dtype=int)\n",
    "\n",
    "    for i in range(0, height, block_size):\n",
    "        for j in range(0, width, block_size):\n",
    "            current_block = frame1[i:i+block_size, j:j+block_size]\n",
    "            best_match = (0, 0)\n",
    "            min_sad = float('inf')\n",
    "\n",
    "            # Search in the given range\n",
    "            for dx in range(-search_range, search_range + 1):\n",
    "                for dy in range(-search_range, search_range + 1):\n",
    "                    ref_x, ref_y = i + dx, j + dy\n",
    "                    if ref_x < 0 or ref_y < 0 or ref_x + block_size > height or ref_y + block_size > width:\n",
    "                        continue\n",
    "                    ref_block = frame2[ref_x:ref_x+block_size, ref_y:ref_y+block_size]\n",
    "                    sad = np.sum(np.abs(current_block - ref_block))\n",
    "                    if sad < min_sad:\n",
    "                        min_sad = sad\n",
    "                        best_match = (dx, dy)\n",
    "\n",
    "            motion_vectors[i // block_size, j // block_size] = best_match\n",
    "    return motion_vectors\n",
    "\n",
    "def motion_compensation(frame, motion_vectors, block_size=BLOCK_SIZE):\n",
    "    predicted_frame = np.zeros_like(frame)\n",
    "\n",
    "    for i in range(0, height, block_size):\n",
    "        for j in range(0, width, block_size):\n",
    "            dx, dy = motion_vectors[i // block_size, j // block_size]\n",
    "            ref_x, ref_y = i + dx, j + dy\n",
    "            predicted_frame[i:i+block_size, j:j+block_size] = frame[ref_x:ref_x+block_size, ref_y:ref_y+block_size]\n",
    "\n",
    "    return predicted_frame\n",
    "\n",
    "### RESIDUAL CALCULATIONS ###\n",
    "def calculate_residual(actual_frame, predicted_frame):\n",
    "    return actual_frame.astype(np.int16) - predicted_frame.astype(np.int16)\n",
    "\n",
    "def reconstruct_frame(predicted_frame, residual):\n",
    "    return predicted_frame + residual\n",
    "\n",
    "### DCT AND QUANTIZATION ###\n",
    "def apply_dct(block):\n",
    "    return dct(dct(block.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def apply_idct(dct_block):\n",
    "    return idct(idct(dct_block.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def quantize_dct(dct_block, quantization_matrix):\n",
    "    return np.round(dct_block / quantization_matrix).astype(np.int16)\n",
    "\n",
    "def dequantize_dct(quantized_block, quantization_matrix):\n",
    "    return (quantized_block * quantization_matrix).astype(np.int16)\n",
    "\n",
    "def run_length_encode(block):\n",
    "    flat_block = np.array(block.flatten(), dtype=int)\n",
    "    encoded = []\n",
    "    prev_value = flat_block[0]\n",
    "    count = 1\n",
    "\n",
    "    for value in flat_block[1:]:\n",
    "        if value == prev_value:\n",
    "            count += 1\n",
    "        else:\n",
    "            encoded.append((int(prev_value), count))\n",
    "            prev_value = value\n",
    "            count = 1\n",
    "    encoded.append((int(prev_value), count))\n",
    "    return encoded\n",
    "\n",
    "def run_length_decode(encoded_block):\n",
    "    decoded_block = []\n",
    "    for value, run_length in encoded_block:\n",
    "        decoded_block.extend([value] * run_length)\n",
    "    return np.array(decoded_block, dtype=int)\n",
    "\n",
    "### FRAME PROCESSING ###\n",
    "def encode_frame(frame):\n",
    "    residual_dct_quantized = np.zeros_like(frame, dtype=float)\n",
    "    encoded_blocks = []\n",
    "\n",
    "    for i in range(0, height, DCT_BLOCK_SIZE):\n",
    "        for j in range(0, width, DCT_BLOCK_SIZE):\n",
    "            block = frame[i:i+DCT_BLOCK_SIZE, j:j+DCT_BLOCK_SIZE]\n",
    "            dct_block = apply_dct(block)\n",
    "            quantized_block = quantize_dct(dct_block, QUANTIZATION_MATRIX)\n",
    "            residual_dct_quantized[i:i+DCT_BLOCK_SIZE, j:j+DCT_BLOCK_SIZE] = quantized_block.astype(int)\n",
    "            encoded_blocks.append(run_length_encode(quantized_block))\n",
    "\n",
    "    return encoded_blocks\n",
    "\n",
    "def decode_frame(encoded_blocks, height, width):\n",
    "    reconstructed_frame = np.zeros((height, width), dtype=float)\n",
    "    block_idx = 0\n",
    "\n",
    "    for i in range(0, height, DCT_BLOCK_SIZE):\n",
    "        for j in range(0, width, DCT_BLOCK_SIZE):\n",
    "            decoded_block_flat = run_length_decode(encoded_blocks[block_idx])\n",
    "            decoded_block = decoded_block_flat.reshape(DCT_BLOCK_SIZE, DCT_BLOCK_SIZE)\n",
    "            dequantize = dequantize_dct(decoded_block, QUANTIZATION_MATRIX)\n",
    "            idct = apply_idct(dequantize)\n",
    "            reconstructed_frame[i:i+DCT_BLOCK_SIZE, j:j+DCT_BLOCK_SIZE] = idct\n",
    "            block_idx += 1\n",
    "\n",
    "    return reconstructed_frame.astype(int)\n",
    "\n",
    "def pipeline(frames, width, height):\n",
    "    # Initialize the compressed frames with the key frame (Y, U, V)\n",
    "    key_frame_y, key_frame_u, key_frame_v = load_frame(frames[0], width, height)\n",
    "    stored_to_write = [(key_frame_y, key_frame_u, key_frame_v)]\n",
    "    compressed_frames = [(key_frame_y, key_frame_u, key_frame_v)]  # Store Y, U, V as tuples\n",
    "    num_to_process = 10\n",
    "\n",
    "\n",
    "    for i in tqdm(range(1, num_to_process)):\n",
    "        current_frame_y, current_frame_u, current_frame_v = load_frame(frames[i], width, height)\n",
    "        \n",
    "        prev_y, prev_u, prev_v = load_frame(frames[-1], width, height)\n",
    "        motion_vectors = motion_estimation(prev_y, current_frame_y)\n",
    "\n",
    "        predicted_frame_y = motion_compensation(prev_y, motion_vectors)\n",
    "\n",
    "        residual_y = calculate_residual(current_frame_y, predicted_frame_y)\n",
    "\n",
    "        encoded_blocks_y = encode_frame(residual_y)\n",
    "\n",
    "        subsampled_u = chroma_subsample_420(current_frame_u)\n",
    "        subsampled_v = chroma_subsample_420(current_frame_v)\n",
    "\n",
    "        stored_to_write.append((motion_vectors, current_frame_u, current_frame_v, encoded_blocks_y))\n",
    "\n",
    "        reconstructed_frame_u = chroma_upsample_420(subsampled_u)\n",
    "        reconstructed_frame_v = chroma_upsample_420(subsampled_v)\n",
    "\n",
    "        reconstructed_residual_y = decode_frame(encoded_blocks_y, height, width)\n",
    "        reconstructed_residual_y = reconstructed_residual_y.astype(residual_y.dtype)\n",
    "        reconstructed_frame_y = reconstruct_frame(predicted_frame_y, residual_y)\n",
    "\n",
    "        reconstructed_frame_y = np.clip(reconstructed_frame_y, 0, 255)\n",
    "        reconstructed_frame_u = np.clip(reconstructed_frame_u, 0, 255)\n",
    "        reconstructed_frame_v = np.clip(reconstructed_frame_v, 0, 255)\n",
    "\n",
    "        ## TODO ADD TRANSFORMATION TO U AND V COMPONENTS\n",
    "\n",
    "        # Combine the reconstructed Y, U, and V channels to form the full frame\n",
    "        reconstructed_frame = (\n",
    "            reconstructed_frame_y,\n",
    "            current_frame_u,\n",
    "            current_frame_v\n",
    "        )\n",
    "\n",
    "        # Append the reconstructed Y, U, and V components to the compressed_frames list\n",
    "        compressed_frames.append(reconstructed_frame)\n",
    "    \n",
    "    return compressed_frames, stored_to_write\n",
    "\n",
    "frames_to_process, store = pipeline(frames, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of inter_test_1.y4m: 3.04\n"
     ]
    }
   ],
   "source": [
    "compressed_to_bytes = frames_into_bytes(frames_to_process)\n",
    "\n",
    "get_output_video(compressed_to_bytes, f'inter_test_1', width=width, height=height, framerate=\"30000:1001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def write_compressed_file(store, filename):\n",
    "    with open(filename, \"wb\") as f:  # Use \"wb\" to write in binary mode\n",
    "        # Keyframe (assuming `store[0]` is the keyframe)\n",
    "        for keyframe in store[0]:\n",
    "            for row in keyframe:\n",
    "                for value in row:\n",
    "                    f.write(struct.pack(\"B\", value))  # Write as a single unsigned byte\n",
    "        \n",
    "        # Encoded frames\n",
    "        for frame in range(1, len(store)):\n",
    "            encoded_blocks = store[frame][3]\n",
    "            motion_vectors = store[frame][0]\n",
    "            u_frame = store[frame][1]\n",
    "            v_frame = store[frame][2]\n",
    "\n",
    "            # Write motion vectors\n",
    "            for row in motion_vectors:\n",
    "                for mv in row:\n",
    "                    f.write(struct.pack(\"bb\", mv[0], mv[1]))  # Write as two signed bytes\n",
    "\n",
    "            # Write U and V frames\n",
    "            for row in u_frame:\n",
    "                for value in row:\n",
    "                    f.write(struct.pack(\"B\", value))  # Write as a single unsigned byte\n",
    "\n",
    "            for row in v_frame:\n",
    "                for value in row:\n",
    "                    f.write(struct.pack(\"B\", value))  # Write as a single unsigned byte\n",
    "\n",
    "            # Write encoded blocks\n",
    "            for block in encoded_blocks:\n",
    "                for combo in block:\n",
    "                    f.write(struct.pack(\"bb\", combo[0], combo[1]))\n",
    "\n",
    "def get_video_from_compressed_file(file, height, width):\n",
    "    with open(file, \"rb\") as f:\n",
    "        for byte in range(height * width):\n",
    "            pass\n",
    "\n",
    "write_compressed_file(store, \"test.compressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "\n",
    "def show_frames(frame1, frame2, frame3, title1=\"Frame 1\", title2=\"Frame 2\", title3=\"Reconstructed Frame 2\"):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Frame 1\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(frame1, cmap='gray')\n",
    "    plt.title(title1)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Frame 2\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(frame2, cmap='gray')\n",
    "    plt.title(title2)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Frame 3\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(frame3, cmap='gray')\n",
    "    plt.title(title3)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
